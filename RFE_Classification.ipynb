{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb5fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "\n",
    "import pickle\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0ef8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Function(s) :\n",
    "\n",
    "def RFE_Features_Classification(indep_X,dep_Y,n):\n",
    "    \n",
    "    RFE_List = []\n",
    "\n",
    "    logistic_Regression = LogisticRegression(solver='lbfgs')\n",
    "    svc_Linear = SVC(kernel = 'linear', random_state = 0)\n",
    "    svc_NonLinear = SVC(kernel = 'rbf', random_state = 0)\n",
    "    gaussianNB = GaussianNB()\n",
    "    kNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    decisionTree = DecisionTreeClassifier(criterion = 'gini',max_features = 'sqrt',splitter = 'best', random_state = 0)\n",
    "    randomForest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        \n",
    "    RFE_Model_List = [logistic_Regression, svc_Linear, svc_NonLinear, gaussianNB, kNN, decisionTree, randomForest]\n",
    "\n",
    "    for i in RFE_Model_List:\n",
    "        print(i)\n",
    "        logistic_RFE = RFE(i,n)\n",
    "        logistic_RFE_Fit = logistic_RFE.fit(indep_X,dep_Y)\n",
    "        logistic_RFE_Feature = logistic_RFE_Fit.transform(indep_X)\n",
    "        RFE_List.append(logistic_RFE_Feature)\n",
    "    return RFE_List\n",
    "\n",
    "def train_test_split_and_StandardScaler(indep_X,dep_Y):\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)    \n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def Confusion_Matrix(classifier,X_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    confusion_matrix = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "    from sklearn.metrics import classification_report \n",
    "    classification_report=classification_report(Y_test, y_pred)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accuracy_score=accuracy_score(Y_test, y_pred)         \n",
    "\n",
    "    return classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score \n",
    "\n",
    "def Logistic_Regression(X_train,Y_train,X_test):       \n",
    "    # Fitting K-NN to the Training set\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    classifier = LogisticRegression(random_state = 0) \n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, Y_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score = Confusion_Matrix(classifier,X_test)\n",
    "    return classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score   \n",
    "\n",
    "def SVM_Linear(X_train,Y_train,X_test):\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, Y_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score = Confusion_Matrix(classifier,X_test)\n",
    "    return classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "def SVM_Non_Linear(X_train,Y_train,X_test):\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, Y_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score = Confusion_Matrix(classifier,X_test)\n",
    "    return classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "def Naive_Bayes(X_train,Y_train,X_test):       \n",
    "\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, Y_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score = Confusion_Matrix(classifier,X_test)\n",
    "    return classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "def KNN(X_train,Y_train,X_test):\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, Y_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score = Confusion_Matrix(classifier,X_test)\n",
    "    return classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "def DecisionTree(X_train,Y_train,X_test):\n",
    "\n",
    "    # Fitting K-NN to the Training set\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, Y_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score = Confusion_Matrix(classifier,X_test)\n",
    "    return classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "def RandomForest(X_train,Y_train,X_test):\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, Y_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score = Confusion_Matrix(classifier,X_test)\n",
    "    return classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "\n",
    "def RFE_Classification(accuracy_LogisticRegression, accuracy_SVM_Linear, accuracy_SVM_NonLinear, \n",
    "                           accuracy_KNN, accuracy_NaiveBayes, accuracy_DecisionTree, accuracy_RandomForest): \n",
    "\n",
    "    dataframe=pd.DataFrame(index=['Logistic Regression', 'SVC', 'Decision Tree', 'Random Forest'],\n",
    "                           columns=['Logistic Regression','SVM Linear','SVM Non Linear','KNN','Naive Bayes',\n",
    "                                    'Decision Tree','Random Forest'])\n",
    "    \n",
    "    #Function - enumerate() acts as a Counter which Iterates index starting from 0 (by default) and their item(s) from the iterable\n",
    "    #Use enumerate() when We need both Position in the loop (number) and its value from the iterable (idex)\n",
    "    \n",
    "    for indexCount,indexValue in enumerate(dataframe.index):      \n",
    "        dataframe['Logistic Regression'][indexValue]=accuracy_LogisticRegression[indexCount]       \n",
    "        dataframe['SVM Linear'][indexValue]=accuracy_SVM_Linear[indexCount]\n",
    "        dataframe['SVM Non Linear'][indexValue]=accuracy_SVM_NonLinear[indexCount]\n",
    "        dataframe['KNN'][indexValue]=accuracy_KNN[indexCount]\n",
    "        dataframe['Naive Bayes'][indexValue]=accuracy_NaiveBayes[indexCount]\n",
    "        dataframe['Decision Tree'][indexValue]=accuracy_DecisionTree[indexCount]\n",
    "        dataframe['Random Forest'][indexValue]=accuracy_RandomForest[indexCount]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae38080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>c</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>12300.000000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>d</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>12400.000000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         bp sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0  2.0  76.459948  c  3.0  0.0  normal  abnormal  notpresent  notpresent   \n",
       "1  3.0  76.459948  c  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "2  4.0  76.459948  a  1.0  0.0  normal    normal  notpresent  notpresent   \n",
       "3  5.0  76.459948  d  1.0  0.0  normal    normal  notpresent  notpresent   \n",
       "4  5.0  50.000000  c  0.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "          bgr  ...        pcv            wc        rc  htn  dm  cad  appet  \\\n",
       "0  148.112676  ...  38.868902   8408.191126  4.705597   no  no   no    yes   \n",
       "1  148.112676  ...  34.000000  12300.000000  4.705597   no  no   no    yes   \n",
       "2   99.000000  ...  34.000000   8408.191126  4.705597   no  no   no    yes   \n",
       "3  148.112676  ...  38.868902   8408.191126  4.705597   no  no   no    yes   \n",
       "4  148.112676  ...  36.000000  12400.000000  4.705597   no  no   no    yes   \n",
       "\n",
       "     pe  ane classification  \n",
       "0   yes   no            yes  \n",
       "1  poor   no            yes  \n",
       "2  poor   no            yes  \n",
       "3  poor  yes            yes  \n",
       "4  poor   no            yes  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.Loading Original Dataset : \n",
    "dataset=pd.read_csv(\"Pre-processed_CKD_Data.csv\",index_col=None)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6bf3629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hrmo</th>\n",
       "      <th>...</th>\n",
       "      <th>pc_normal</th>\n",
       "      <th>pcc_present</th>\n",
       "      <th>ba_present</th>\n",
       "      <th>htn_yes</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>cad_yes</th>\n",
       "      <th>appet_yes</th>\n",
       "      <th>pe_yes</th>\n",
       "      <th>ane_yes</th>\n",
       "      <th>classification_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>57.482105</td>\n",
       "      <td>3.077356</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>12.518156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         bp   al   su         bgr         bu        sc         sod  \\\n",
       "0  2.0  76.459948  3.0  0.0  148.112676  57.482105  3.077356  137.528754   \n",
       "1  3.0  76.459948  2.0  0.0  148.112676  22.000000  0.700000  137.528754   \n",
       "2  4.0  76.459948  1.0  0.0   99.000000  23.000000  0.600000  138.000000   \n",
       "3  5.0  76.459948  1.0  0.0  148.112676  16.000000  0.700000  138.000000   \n",
       "4  5.0  50.000000  0.0  0.0  148.112676  25.000000  0.600000  137.528754   \n",
       "\n",
       "        pot       hrmo  ...  pc_normal  pcc_present  ba_present  htn_yes  \\\n",
       "0  4.627244  12.518156  ...          0            0           0        0   \n",
       "1  4.627244  10.700000  ...          1            0           0        0   \n",
       "2  4.400000  12.000000  ...          1            0           0        0   \n",
       "3  3.200000   8.100000  ...          1            0           0        0   \n",
       "4  4.627244  11.800000  ...          1            0           0        0   \n",
       "\n",
       "   dm_yes  cad_yes  appet_yes  pe_yes  ane_yes  classification_yes  \n",
       "0       0        0          1       1        0                   1  \n",
       "1       0        0          1       0        0                   1  \n",
       "2       0        0          1       0        0                   1  \n",
       "3       0        0          1       0        1                   1  \n",
       "4       0        0          1       0        0                   1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.Duplicating the Original Dataset\n",
    "dataset2 = dataset\n",
    "\n",
    "#3.Classifying the Nominal Columns in Dataset : \n",
    "dataset2 = pd.get_dummies(dataset2, drop_first=True)\n",
    "print(dataset2.shape)\n",
    "dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce24589f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 27)\n",
      "(399,)\n"
     ]
    }
   ],
   "source": [
    "#4.Assigning Variables (Independent/Dependent) : \n",
    "\n",
    "indep_X = dataset2.drop('classification_yes', 1)\n",
    "print(indep_X.shape)\n",
    "\n",
    "dep_Y = dataset2['classification_yes']\n",
    "print(dep_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28a1de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\utils\\fixes.py:230: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The classifier does not expose \"coef_\" or \"feature_importances_\" attributes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8184\\2986541632.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#5.Calling a Created Function - RFE_Features_Classification(indep_X,dep_Y,n): which returns - RFE_Features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Here the Example number = 5 as Feature Selection which takes 5 Parameters as Input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mRFE_List\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE_Features_Classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindep_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdep_Y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Creating Empty Lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8184\\2340539576.py\u001b[0m in \u001b[0;36mRFE_Features_Classification\u001b[1;34m(indep_X, dep_Y, n)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mlogistic_RFE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mlogistic_RFE_Fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_RFE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindep_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdep_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mlogistic_RFE_Feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_RFE_Fit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindep_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mRFE_List\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogistic_RFE_Feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \"\"\"\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\AI_ML\\lib\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, step_score)\u001b[0m\n\u001b[0;32m    189\u001b[0m                 \u001b[0mcoefs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'feature_importances_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcoefs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m                 raise RuntimeError('The classifier does not expose '\n\u001b[0m\u001b[0;32m    192\u001b[0m                                    \u001b[1;34m'\"coef_\" or \"feature_importances_\" '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                                    'attributes')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The classifier does not expose \"coef_\" or \"feature_importances_\" attributes"
     ]
    }
   ],
   "source": [
    "#5.Calling a Created Function - RFE_Features_Classification(indep_X,dep_Y,n): which returns - RFE_Features\n",
    "#Here the Example number = 5 as Feature Selection which takes 5 Parameters as Input\n",
    "RFE_List = RFE_Features_Classification(indep_X,dep_Y,6)       \n",
    "\n",
    "#Creating Empty Lists\n",
    "accuracy_LogisticRegression = []\n",
    "accuracy_SVM_Linear = []\n",
    "accuracy_SVM_NonLinear = []\n",
    "accuracy_KNN = []\n",
    "accuracy_NaiveBayes = []\n",
    "accuracy_DecisionTree = []\n",
    "accuracy_RandomForest = []\n",
    "\n",
    "for i in RFE_List:\n",
    "    \n",
    "    #6.Calling a Created Function - train_test_split_and_StandardScaler: which returns - X_train, X_test, Y_train, Y_test\n",
    "    #Hence, Passing (i, dep_Y) along with Selected Number of Features instead of K_Best (k_Best, dep_Y)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split_and_StandardScaler(i, dep_Y)   \n",
    "\n",
    "    #Creating Various Models as follows :\n",
    "\n",
    "    #7.Calling a Created Function - LogisticRegression(X_train,Y_train,X_test): which returns - classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score\n",
    "    classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score = LogisticRegression(X_train,Y_train,X_test)\n",
    "    accuracy_LogisticRegression.append(accuracy_score)\n",
    "\n",
    "    #8.Calling a Created Function - SVM_Linear(X_train,Y_train,X_test): which returns - classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score\n",
    "    classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score = SVM_Linear(X_train,Y_train,X_test)  \n",
    "    accuracy_SVM_Linear.append(accuracy_score)\n",
    "\n",
    "    #9.Calling a Created Function - SVM_Non_Linear(X_train,Y_train,X_test): which returns - classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score\n",
    "    classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score = SVM_Non_Linear(X_train,Y_train,X_test)  \n",
    "    accuracy_SVM_NonLinear.append(accuracy_score)\n",
    "\n",
    "    #10.Calling a Created Function - KNN(X_train,Y_train,X_test): which returns - classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score\n",
    "    classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score = KNN(X_train,Y_train,X_test)  \n",
    "    accuracy_KNN.append(accuracy_score)\n",
    "\n",
    "    #11.Calling a Created Function - Naive_Bayes(X_train,Y_train,X_test): which returns - classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score\n",
    "    classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score = Naive_Bayes(X_train,Y_train,X_test)  \n",
    "    accuracy_NaiveBayes.append(accuracy_score)\n",
    "\n",
    "    #12.Calling a Created Function - DecisionTree(X_train,Y_train,X_test): which returns - classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score\n",
    "    classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score = DecisionTree(X_train,Y_train,X_test)  \n",
    "    accuracy_DecisionTree.append(accuracy_score)\n",
    "\n",
    "    #13.Calling a Created Function - RandomForest(X_train,Y_train,X_test): which returns - classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score\n",
    "    classifier, X_test, Y_test, confusion_matrix, classification_report, accuracy_score = RandomForest(X_train,Y_train,X_test)  \n",
    "    accuracy_RandomForest.append(accuracy_score)\n",
    "\n",
    "#14.Calling a Created Function - RFE_Classification(With Below Parameters): which returns - dataframe    \n",
    "result=RFE_Classification(accuracy_LogisticRegression, accuracy_SVM_Linear, accuracy_SVM_NonLinear, \n",
    "                               accuracy_KNN, accuracy_NaiveBayes, accuracy_DecisionTree, accuracy_RandomForest)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Final Results by Selecting Top 6 Features\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3017da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Final Results by Selecting Top 5 Features\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4893b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Final Results by Selecting Top 4 Features\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c78b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Final Results by Selecting Top 3 Features\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Final Results by Selecting Top 2 Features\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7e7535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the Final Results by Selecting Top 1 Feature\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4334bbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
